---
title: "Homework 5"
output: github_document
---


```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(gapminder)
library(singer)
library(tidyverse)
library(knitr)
library(ggthemes)
library(reshape2)
library(dplyr)
library(ggplot2)
library(forcats)
library(gdata)
```

I decided to work with the singer dataset for a change :smile:

## Factor Management

**Factorize.** Transform some of the variable in the `singer_locations` dataframe into factors: pay attention at what levels you introduce and their order. Try and consider the difference between the base R `as.factor` and the `forcats`-provided functions.

First I just want to inspect the data: 
```{r}
data("singer_locations")
kable(head(singer_locations))
```

First I tried to factorize city with the `as_factor` used in class (cm012) but that didn't work. This seems to be due to the existance of NA values. (Here I presented the code as a block quote since knitr wont render a file with code errors.)

> sl_fac <-singer_locations %>% 
  mutate(city_factor = as_factor(city))

>Output: Error in mutate_impl(.data, dots) : Evaluation error: `idx` must contain one integer for each level of `f`.

Remove NA's and then run: 

```{r}
singer_locations %>% 
  filter(!is.na(city)) %>% 
  mutate(city_factor = as_factor(city)) 
kable(head(singer_locations %>% 
  filter(!is.na(city)) %>% 
  mutate(city_factor = as_factor(city)) ))
```

Alternatively, base R also comes with `as.factor`: 
```{r}
sl_facB <- singer_locations %>% 
  mutate(city_factor = as.factor(city)) 
kable(head(sl_facB))
```

A third way is to just use `forcats`. This is often advised since we probably don't want to be reordering our factor which can happen with the base r versions. 
```{r}
sl_facF <- singer_locations %>% 
  mutate(city_factor = factor(city))
kable(head(sl_facF))
```

All of these ways to factor appear to give the same results for our dataset so it probaly doesn't matter which one we go with here. 

**Drop 0.** Filter the `singer_locations` data to remove observations associated with the uncorrectly inputed `year` 0. Additionally, remove unused factor levels. Provide concrete information on the data before and after removing these rows and levels; address the number of rows and the levels of the affected factors.

Prior to removal there were 10100 observations 

```{r}
str(sl_facF)
```
 
 Now with removal of year 0: we are left with 10000 observations

```{r}
sl_facFYear <- (filter(sl_facF, year != "0")) 
    str(sl_facFYear)
```
**Second part of the quesiton:** Additionally, remove unused factor levels. Provide concrete information on the data before and after removing these rows and levels; address the number of rows and the levels of the affected factors.

I for my factor city, there are a numbe of NA values. 
```{r}
sl_facF_cityna <- (sl_facFYear %>% 
    filter(!is.na(city)))
  str(sl_facF_cityna)
```
After removing those we can see that were are 4090 observations with 1316 factor levels for city_factor. 

In examining the data though there are a few odd factors like "?, Illinois, 020, 27, 310 Lousiana, 732 New Jersey" I decided to remove these as well. 

```{r}
sl_new <- (sl_facFYear %>% 
filter( city_factor != "?, Illinois")  %>% 
  filter( city_factor != "020") %>% 
  filter( city_factor != "310, Louisiana") %>% 
  filter( city_factor != "732, NEW JERSEY, USA") %>% 
  filter( city_factor != "27")) 
    str(sl_new) 
```

The structure now indicates that there are only 4083 observations. However, it does still list "?, Illinois". Just to check I tried to call up one of the removed items. 
```{r}
sl_new %>% 
filter(city_factor == "?, Illinois") 
```

It did indead remove the value but I guess it still remembers it as a factor that did exist at one point. To remove the levels first I used the forcats method: 


```{r}
sl_new4 <- sl_new$city_factor %>%
  fct_drop() %>% 
str(sl_new4)
```
This seems to only retain this particular vector. 

After searching the web, I found this code:
```{r}
sl_new2 <-(droplevels(sl_new)$city_factor)
str(sl_new2)
```
Okay, this code just created a new table but got rid of all my other data... 

I found on [R-bloggers](https://www.r-bloggers.com/r-drop-factor-levels-in-a-dataset/) advice to use `gdata` package to remove factor levels while retaining your other data. This seems to have worked and retained all the other data I want. 
```{r}
sl_new3 <- drop.levels(sl_new) 
str(sl_new3)
```


**Reorder the levels of `year`, `artist_name` or `title`.** Use the forcats package to change the order of the factor levels, based on a principled summary of one of the quantitative variables. Consider experimenting with a summary statistic beyond the most basic choice of the median.

I decided to reorder `artist_name` by maximum of song duration but since this is so much data and the next step is a graph - I filtered to only before 1990 and only in Philadelphia which seemed to be a popular location. First I had to factorize `artist_name`, then create a summarized coloumn of duration maximum for each artist name. But then I ran into an issue that you can't factor reorder a grouping variable. To solve this I took my newly created `sl_summary` which had the summary statistic that I wanted and left joined it with `sl_new3`

This seems to have worked perfectly. 

```{r}
sl_small2 <- (sl_new3 %>% 
  filter(year <= 1990 & city=="Philadelphia, PA"))
sl_summary2 <- (sl_small2 %>% 
  group_by(artist_name) %>% 
  summarize(MaxDur=max(duration))) %>% 
  mutate(artist_name_factor = factor(artist_name)) 
sl_order <- (sl_summary2 %>% 
  mutate(artist_name_factor=fct_reorder(artist_name_factor,MaxDur)))
levels(sl_order$artist_name_factor)
```


**Common part:**
Explore effects of `arrange()`: 


```{r}
sl_arange <- sl_summary2 %>% 
  arrange(MaxDur) %>% 
  ggplot(aes(artist_name_factor, MaxDur)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x="Artist", 
          y="Maximum Song Duration",
          title="Maximum Song Duration by Artists in Philly before the 90s")

sl_arange
```




Now with the `factor_reorder` and the `arrange` function: 

```{r}
sl_FOrder <- sl_summary2 %>% 
  mutate(artist_name_factor=fct_reorder(artist_name_factor,MaxDur)) %>% 
  arrange(MaxDur) %>% 
  ggplot(aes(artist_name_factor, MaxDur)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x="Artist", 
          y="Maximum Song Duration",
          title="Maximum Song Duration by Artists in Philly before the 90s")

sl_FOrder
```

I was surprised that the `factor_reorder` function needed `arrange` to work so I tried it just the `factor_reorder` function: 

```{r}
sl_FOrder <- sl_summary2 %>% 
  mutate(artist_name_factor=fct_reorder(artist_name_factor,MaxDur)) %>% 
  ggplot(aes(artist_name_factor, MaxDur)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x="Artist", 
          y="Maximum Song Duration",
          title="Maximum Song Duration by Artists in Philly before the 90s")

sl_FOrder
```

It seems to have done the same thing as before. This is much easier to read with the `factor_reorder` function: it is clear to see the differences between artistis in the middle - (e.g., that The Delfonics had a larger maximum duration than Bill Cosby).


**File I/O**
For this part I decided to reorder city by artist_hotttnesss. Here is the orignal head data layout: 

```{r}
City_hotness <- (singer_locations %>% 
  filter(latitude >=30) %>% 
  mutate(city_factor = factor(city)) %>% 
  mutate(city_factor=fct_reorder(city_factor,artist_hotttnesss)))
  kable(head(City_hotness))
```

First I wrote this to csv and then read it back in: 

```{r}
write_csv(City_hotness, "City_hotness.csv")
City_hotnessCSV <-read_csv("City_hotness.csv")
kable(head(City_hotnessCSV))
```

CSV formatting seems to have maintained our previous ordering of city by artist hotttnesss. 

Next I tried RDS
```{r}
saveRDS(City_hotness, "City_hotness.csv")
City_hotnessRDS <-readRDS("City_hotness.csv")
kable(head(City_hotnessRDS))
```

RDS also seems fine with retaining our ordering of city. 

Now to try dput: which also seems fine
```{r}
dput(City_hotness, "City_hotness")
City_hotnessDput <-dget("City_hotness")
kable(head(City_hotness))
```

Next I tried deliminated: where our data seemed to fall apart: 
```{r}
write_delim(City_hotness, "City_hotness")
City_hotnessDelim <-read.delim("City_hotness")
(head(City_hotnessDelim))
```

**Visualization design** 

```{r}
singer_locations %>% 
  summary(artist_hotttnesss)
```

Here I decided to examine artist hotttnesss by year. After trying this plot the first time I realized that I needed to remove 0s from both these variables. 
```{r}
plot1 <- singer_locations %>% 
  filter( year != "0") %>% 
  filter(artist_hotttnesss != "0") %>% 
  mutate(hotness=c("Hot", "Not")[(artist_hotttnesss>mean(artist_hotttnesss)) + 1]) %>%
  ggplot(aes(year, artist_hotttnesss, color = hotness)) + geom_point(alpha = .2)
plot1
```

Here I tried to show artist hotttness by latitude but had some issues with the full range of data showing up and being legible. 
```{r}
plot2 <- singer_locations %>% 
  filter(!is.na(latitude)) %>% 
  filter(artist_hotttnesss != "0") %>% 
  ggplot(aes(artist_hotttnesss, latitude, color = latitude)) +
  geom_point(alpha = .7) + 
  scale_colour_gradient2(low="blue", mid="white", high="red", midpoint = 40.02, "Latitude")
plot2
```

One of Tamara Munzner's suggests was to use Viridis which has scales based on luminance. I also realized how redundant this was to just have the two variables and a repeat by color so I decided to plot artist familiarity too. 

```{r}
library(viridis)
plot2 <- singer_locations %>% 
  filter(!is.na(latitude)) %>% 
  filter(artist_hotttnesss != "0") %>% 
  ggplot(aes(artist_hotttnesss, latitude, color = artist_familiarity))  +
  geom_point(alpha = .2) + 
  scale_fill_viridis()
plot2
```

We can see form this data that there is more data in the north but also seems like lower overall ratings of familiarity. 

It is super hard to read the previous graph with so much data clustered in the north. So here I separated it out by longitude too. 

```{r}
library(viridis)
plot3 <- singer_locations %>% 
  filter(!is.na(latitude)) %>% 
  filter(artist_hotttnesss != "0") %>% 
  filter(year != "0") %>% 
  ggplot(aes(longitude, latitude, color = artist_familiarity)) +
  geom_point(alpha = .5) + 
  scale_fill_viridis()
plot3
```

Again this is pretty clusted but seems to show the most familiar artists are in the Europe and USA. Here I am going to zoom in on the UK. 

```{r}
library(viridis)
plot4 <- singer_locations %>% 
  filter(!is.na(latitude)) %>% 
  filter(latitude >=20  & longitude > -10 & longitude < 50) %>% 
  filter(artist_hotttnesss != "0") %>% 
  filter(year != "0") %>% 
  ggplot(aes(longitude, latitude, color = artist_hotttnesss)) +
  geom_point(alpha = .5) + 
  scale_colour_viridis(option="inferno") 
plot4
```

It is still pretty hard to read because of crowding

```{r}
library(viridis)
plot4 <- singer_locations %>% 
  filter(!is.na(latitude)) %>% 
  filter(latitude >=20  & longitude > -10 & longitude < 50) %>% 
  filter(artist_hotttnesss != "0") %>% 
  filter(year != "0") %>% 
  ggplot(aes(longitude, latitude, color = artist_hotttnesss)) +
  geom_point(alpha = .2) + 
  scale_colour_viridis(option="inferno") 
plot4
```

